{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ijR6qPINU_P6",
    "outputId": "c6246325-d2c1-40b3-9319-5859294d987f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ece405-assignment1-basics' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/bushuyeu/ece405-assignment1-basics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S5eKjGhFMiZ6",
    "outputId": "49892466-3dad-4597-b80c-8e7983f1aa04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/ece405-assignment1-basics\n"
     ]
    }
   ],
   "source": [
    "%cd ece405-assignment1-basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVh85UKdMng8",
    "outputId": "76d7ce15-62a5-4139-bdd1-065eb8109f8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 8, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 5 (delta 2), reused 5 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
      "Unpacking objects: 100% (5/5), 11.37 KiB | 5.69 MiB/s, done.\n",
      "From https://github.com/bushuyeu/ece405-assignment1-basics\n",
      "   4f5366b..1006af1  main       -> origin/main\n",
      "Updating 4f5366b..1006af1\n",
      "Fast-forward\n",
      " ECE405_Homework1_ipynb_Pavel_Bushuyeu.ipynb | 827 \u001b[32m++++++++++++++++++++++++++++\u001b[m\n",
      " scripts/train_bpe_tinystories.py            |  11 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
      " 2 files changed, 836 insertions(+), 2 deletions(-)\n",
      " create mode 100644 ECE405_Homework1_ipynb_Pavel_Bushuyeu.ipynb\n"
     ]
    }
   ],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MLdwVyZ3MKk8",
    "outputId": "44167e78-4b8d-43a4-aeff-1e422cc64563"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already on 'main'\n",
      "Your branch is up to date with 'origin/main'.\n"
     ]
    }
   ],
   "source": [
    "!git checkout main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUpCszLnfDf1"
   },
   "source": [
    "No need for Conda environment on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D1tPK7iKenBW",
    "outputId": "7980fd43-6840-4859-c8db-9a3c8b7d6843"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///content/ece405-assignment1-basics\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: einops>=0.8.1 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.8.2)\n",
      "Collecting einx>=0.3.0 (from cs336-basics==1.0.6)\n",
      "  Using cached einx-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting jaxtyping>=0.3.0 (from cs336-basics==1.0.6)\n",
      "  Using cached jaxtyping-0.3.7-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (2.0.2)\n",
      "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (7.2.2)\n",
      "Requirement already satisfied: pytest>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (8.4.2)\n",
      "Requirement already satisfied: regex>=2024.11.6 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (2025.11.3)\n",
      "Requirement already satisfied: submitit>=1.5.2 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (1.5.4)\n",
      "Requirement already satisfied: tiktoken>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.12.0)\n",
      "Collecting torch~=2.6.0 (from cs336-basics==1.0.6)\n",
      "  Using cached torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: tqdm>=4.67.1 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (4.67.1)\n",
      "Requirement already satisfied: wandb>=0.19.7 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.24.0)\n",
      "Requirement already satisfied: ty>=0.0.1a16 in /usr/local/lib/python3.12/dist-packages (from cs336-basics==1.0.6) (0.0.15)\n",
      "\u001b[33mWARNING: cs336-basics 1.0.6 does not provide the extra 'test'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->cs336-basics==1.0.6) (1.13.1)\n",
      "Requirement already satisfied: frozendict in /usr/local/lib/python3.12/dist-packages (from einx>=0.3.0->cs336-basics==1.0.6) (2.4.7)\n",
      "Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from jaxtyping>=0.3.0->cs336-basics==1.0.6) (0.1.7)\n",
      "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (2.3.0)\n",
      "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (25.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest>=8.3.4->cs336-basics==1.0.6) (2.19.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.1 in /usr/local/lib/python3.12/dist-packages (from submitit>=1.5.2->cs336-basics==1.0.6) (3.1.2)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from submitit>=1.5.2->cs336-basics==1.0.6) (4.15.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken>=0.9.0->cs336-basics==1.0.6) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.20.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (10.3.5.147)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.6.0->cs336-basics==1.0.6)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch~=2.6.0->cs336-basics==1.0.6) (75.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->einx>=0.3.0->cs336-basics==1.0.6) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (8.3.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (3.1.46)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (4.5.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (5.29.5)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (2.12.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (6.0.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.19.7->cs336-basics==1.0.6) (2.51.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.19.7->cs336-basics==1.0.6) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.19.7->cs336-basics==1.0.6) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken>=0.9.0->cs336-basics==1.0.6) (2026.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch~=2.6.0->cs336-basics==1.0.6) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.19.7->cs336-basics==1.0.6) (5.0.2)\n",
      "Using cached einx-0.3.0-py3-none-any.whl (102 kB)\n",
      "Using cached jaxtyping-0.3.7-py3-none-any.whl (56 kB)\n",
      "Using cached torch-2.6.0-cp312-cp312-manylinux1_x86_64.whl (766.6 MB)\n",
      "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "Building wheels for collected packages: cs336-basics\n",
      "  Building editable for cs336-basics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cs336-basics: filename=cs336_basics-1.0.6-py3-none-any.whl size=3234 sha256=b18d060760a0edb776e46debc7cf78a1e33ad6dcdfeecf431a45556c4636ac03\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qi7v6ev8/wheels/9c/8e/ad/47aa51c5b697fa6e79290e71856f3cf535f60484b164938fb6\n",
      "Successfully built cs336-basics\n",
      "Installing collected packages: nvidia-cudnn-cu12, jaxtyping, nvidia-cusolver-cu12, einx, torch, cs336-basics\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0+cu126\n",
      "    Uninstalling torch-2.9.0+cu126:\n",
      "      Successfully uninstalled torch-2.9.0+cu126\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.24.0+cu126 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cs336-basics-1.0.6 einx-0.3.0 jaxtyping-0.3.7 nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.6.1.9 torch-2.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -e .'[test]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J-_dABLeW3LR",
    "outputId": "787494f1-291c-4413-b4f5-648cf956828f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.12.12, pytest-8.4.2, pluggy-1.6.0\n",
      "rootdir: /content/ece405-assignment1-basics\n",
      "configfile: pytest.ini\n",
      "plugins: jaxtyping-0.3.7, langsmith-0.6.6, typeguard-4.4.4, anyio-4.12.1\n",
      "collected 3 items                                                              \u001b[0m\n",
      "\n",
      "tests/test_train_bpe.py::test_train_bpe_speed \u001b[31mFAILED\u001b[0m\u001b[31m                     [ 33%]\u001b[0m\n",
      "tests/test_train_bpe.py::test_train_bpe \u001b[31mFAILED\u001b[0m\u001b[31m                           [ 66%]\u001b[0m\n",
      "tests/test_train_bpe.py::test_train_bpe_special_tokens \u001b[31mFAILED\u001b[0m\u001b[31m            [100%]\u001b[0m\n",
      "\n",
      "=================================== FAILURES ===================================\n",
      "\u001b[31m\u001b[1m_____________________________ test_train_bpe_speed _____________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_bpe_speed\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Ensure that BPE training is relatively efficient by measuring training\u001b[39;49;00m\n",
      "    \u001b[33m    time on this small dataset and throwing an error if it takes more than 1.5 seconds.\u001b[39;49;00m\n",
      "    \u001b[33m    This is a pretty generous upper-bound, it takes 0.38 seconds with the\u001b[39;49;00m\n",
      "    \u001b[33m    reference implementation on my laptop. In contrast, the toy implementation\u001b[39;49;00m\n",
      "    \u001b[33m    takes around 3 seconds.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        input_path = FIXTURES_PATH / \u001b[33m\"\u001b[39;49;00m\u001b[33mcorpus.en\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        start_time = time.time()\u001b[90m\u001b[39;49;00m\n",
      ">       _, _ = run_train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "            input_path=input_path,\u001b[90m\u001b[39;49;00m\n",
      "            vocab_size=\u001b[94m500\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            special_tokens=[\u001b[33m\"\u001b[39;49;00m\u001b[33m<|endoftext|>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_train_bpe.py\u001b[0m:18: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/adapters.py\u001b[0m:594: in run_train_bpe\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:249: in train_bpe\n",
      "    \u001b[0mheap.update(new_pair, pair_counts[new_pair], vocab)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ece496b_basics.MaxHeap object at 0x7f95175602f0>, pair = (256, 105)\n",
      "count = 1, vocab = {0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', ...}\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mupdate\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, pair: Tuple[\u001b[96mint\u001b[39;49;00m, \u001b[96mint\u001b[39;49;00m], count: \u001b[96mint\u001b[39;49;00m, vocab: Dict[\u001b[96mint\u001b[39;49;00m, \u001b[96mbytes\u001b[39;49;00m]):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Update count for a pair (lazy deletion - just add new entry).\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._valid[pair] = count               \u001b[90m# Update valid count\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m count > \u001b[94m0\u001b[39;49;00m:                           \u001b[90m# Only add if positive\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">           heapq.heappush(\u001b[96mself\u001b[39;49;00m._heap, (-count, vocab[pair[\u001b[94m0\u001b[39;49;00m]], vocab[pair[\u001b[94m1\u001b[39;49;00m]], pair))\u001b[90m\u001b[39;49;00m\n",
      "                                                ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           KeyError: 256\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:108: KeyError\n",
      "\u001b[31m\u001b[1m________________________________ test_train_bpe ________________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_bpe\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "        input_path = FIXTURES_PATH / \u001b[33m\"\u001b[39;49;00m\u001b[33mcorpus.en\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       vocab, merges = run_train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "            input_path=input_path,\u001b[90m\u001b[39;49;00m\n",
      "            vocab_size=\u001b[94m500\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            special_tokens=[\u001b[33m\"\u001b[39;49;00m\u001b[33m<|endoftext|>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_train_bpe.py\u001b[0m:29: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/adapters.py\u001b[0m:594: in run_train_bpe\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:249: in train_bpe\n",
      "    \u001b[0mheap.update(new_pair, pair_counts[new_pair], vocab)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ece496b_basics.MaxHeap object at 0x7f9516d9f020>, pair = (256, 105)\n",
      "count = 1, vocab = {0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', ...}\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mupdate\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, pair: Tuple[\u001b[96mint\u001b[39;49;00m, \u001b[96mint\u001b[39;49;00m], count: \u001b[96mint\u001b[39;49;00m, vocab: Dict[\u001b[96mint\u001b[39;49;00m, \u001b[96mbytes\u001b[39;49;00m]):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Update count for a pair (lazy deletion - just add new entry).\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._valid[pair] = count               \u001b[90m# Update valid count\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m count > \u001b[94m0\u001b[39;49;00m:                           \u001b[90m# Only add if positive\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">           heapq.heappush(\u001b[96mself\u001b[39;49;00m._heap, (-count, vocab[pair[\u001b[94m0\u001b[39;49;00m]], vocab[pair[\u001b[94m1\u001b[39;49;00m]], pair))\u001b[90m\u001b[39;49;00m\n",
      "                                                ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           KeyError: 256\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:108: KeyError\n",
      "\u001b[31m\u001b[1m________________________ test_train_bpe_special_tokens _________________________\u001b[0m\n",
      "\n",
      "snapshot = <tests.conftest.Snapshot object at 0x7f95169ac200>\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mtest_train_bpe_special_tokens\u001b[39;49;00m(snapshot):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"\u001b[39;49;00m\n",
      "    \u001b[33m    Ensure that the special tokens are added to the vocabulary and not\u001b[39;49;00m\n",
      "    \u001b[33m    merged with other tokens.\u001b[39;49;00m\n",
      "    \u001b[33m    \"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        input_path = FIXTURES_PATH / \u001b[33m\"\u001b[39;49;00m\u001b[33mtinystories_sample_5M.txt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">       vocab, merges = run_train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "            input_path=input_path,\u001b[90m\u001b[39;49;00m\n",
      "            vocab_size=\u001b[94m1000\u001b[39;49;00m,\u001b[90m\u001b[39;49;00m\n",
      "            special_tokens=[\u001b[33m\"\u001b[39;49;00m\u001b[33m<|endoftext|>\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\u001b[90m\u001b[39;49;00m\n",
      "        )\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mtests/test_train_bpe.py\u001b[0m:71: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\u001b[1m\u001b[31mtests/adapters.py\u001b[0m:594: in run_train_bpe\n",
      "    \u001b[0m\u001b[94mreturn\u001b[39;49;00m train_bpe(\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:249: in train_bpe\n",
      "    \u001b[0mheap.update(new_pair, pair_counts[new_pair], vocab)\u001b[90m\u001b[39;49;00m\n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "self = <ece496b_basics.MaxHeap object at 0x7f9517339a60>, pair = (115, 256)\n",
      "count = 21, vocab = {0: b'\\x00', 1: b'\\x01', 2: b'\\x02', 3: b'\\x03', ...}\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m\u001b[90m \u001b[39;49;00m\u001b[92mupdate\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, pair: Tuple[\u001b[96mint\u001b[39;49;00m, \u001b[96mint\u001b[39;49;00m], count: \u001b[96mint\u001b[39;49;00m, vocab: Dict[\u001b[96mint\u001b[39;49;00m, \u001b[96mbytes\u001b[39;49;00m]):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"Update count for a pair (lazy deletion - just add new entry).\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[96mself\u001b[39;49;00m._valid[pair] = count               \u001b[90m# Update valid count\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m count > \u001b[94m0\u001b[39;49;00m:                           \u001b[90m# Only add if positive\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">           heapq.heappush(\u001b[96mself\u001b[39;49;00m._heap, (-count, vocab[pair[\u001b[94m0\u001b[39;49;00m]], vocab[pair[\u001b[94m1\u001b[39;49;00m]], pair))\u001b[90m\u001b[39;49;00m\n",
      "                                                                ^^^^^^^^^^^^^^\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           KeyError: 256\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31mece496b_basics/__init__.py\u001b[0m:108: KeyError\n",
      "\u001b[36m\u001b[1m=========================== short test summary info ============================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m tests/test_train_bpe.py::\u001b[1mtest_train_bpe_speed\u001b[0m - KeyError: 256\n",
      "\u001b[31mFAILED\u001b[0m tests/test_train_bpe.py::\u001b[1mtest_train_bpe\u001b[0m - KeyError: 256\n",
      "\u001b[31mFAILED\u001b[0m tests/test_train_bpe.py::\u001b[1mtest_train_bpe_special_tokens\u001b[0m - KeyError: 256\n",
      "\u001b[31m============================== \u001b[31m\u001b[1m3 failed\u001b[0m\u001b[31m in 1.84s\u001b[0m\u001b[31m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest tests/test_train_bpe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "5wrA646Gf3Ht",
    "outputId": "aaecca5f-2ea3-462c-9789-fa8d38a2d752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "/content/data\n",
      "--2026-02-05 03:24:36--  https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\n",
      "Resolving huggingface.co (huggingface.co)... 3.165.160.59, 3.165.160.61, 3.165.160.12, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.165.160.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/02e40cc51c59a4bc6c51bd7bc9acda4316e208745be060558eaf500cd14e9f96?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27TinyStoriesV2-GPT4-train.txt%3B+filename%3D%22TinyStoriesV2-GPT4-train.txt%22%3B&response-content-type=text%2Fplain&Expires=1770265476&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NDc2fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ1ZThkYTk2MzIwYjBlZmU0MGFkZTdhLzAyZTQwY2M1MWM1OWE0YmM2YzUxYmQ3YmM5YWNkYTQzMTZlMjA4NzQ1YmUwNjA1NThlYWY1MDBjZDE0ZTlmOTZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=KzG2CD2PG-y7K9xpHXjWxOBis9%7EuIIXF%7EY-THNxi63kVm5wDkpm1qYAzXsexplqFsjr3tCdQtXmG%7E3miG--kFZBUSYdHIZ8EUbjrcvFj23r5C05LXJQPyP1Aw1DqvxaXVhahPqZAxB00XT626lS206gDF5SmtkKclGxlAu0SIOCpkHQUDVV7QnJ3co2e8MgzDlY0eSNd-Tj-BSbkfvkYWw%7Ev9h93aVk-piAEVr9sEO4tbD66Dnes4MFfNSGdO2apOrUNHDYiSGgy%7Ev-MauKj%7EPcKrnz8jKZyG7-HfF254pnT47IsJQLmK%7EubnVehhlotxkfo977wV7d7%7E0cNmML86w__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
      "--2026-02-05 03:24:36--  https://us.gcp.cdn.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/02e40cc51c59a4bc6c51bd7bc9acda4316e208745be060558eaf500cd14e9f96?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27TinyStoriesV2-GPT4-train.txt%3B+filename%3D%22TinyStoriesV2-GPT4-train.txt%22%3B&response-content-type=text%2Fplain&Expires=1770265476&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NDc2fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ1ZThkYTk2MzIwYjBlZmU0MGFkZTdhLzAyZTQwY2M1MWM1OWE0YmM2YzUxYmQ3YmM5YWNkYTQzMTZlMjA4NzQ1YmUwNjA1NThlYWY1MDBjZDE0ZTlmOTZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=KzG2CD2PG-y7K9xpHXjWxOBis9%7EuIIXF%7EY-THNxi63kVm5wDkpm1qYAzXsexplqFsjr3tCdQtXmG%7E3miG--kFZBUSYdHIZ8EUbjrcvFj23r5C05LXJQPyP1Aw1DqvxaXVhahPqZAxB00XT626lS206gDF5SmtkKclGxlAu0SIOCpkHQUDVV7QnJ3co2e8MgzDlY0eSNd-Tj-BSbkfvkYWw%7Ev9h93aVk-piAEVr9sEO4tbD66Dnes4MFfNSGdO2apOrUNHDYiSGgy%7Ev-MauKj%7EPcKrnz8jKZyG7-HfF254pnT47IsJQLmK%7EubnVehhlotxkfo977wV7d7%7E0cNmML86w__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
      "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
      "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2227753162 (2.1G) [text/plain]\n",
      "Saving to: ‘TinyStoriesV2-GPT4-train.txt’\n",
      "\n",
      "TinyStoriesV2-GPT4- 100%[===================>]   2.07G  91.2MB/s    in 30s     \n",
      "\n",
      "2026-02-05 03:25:06 (71.1 MB/s) - ‘TinyStoriesV2-GPT4-train.txt’ saved [2227753162/2227753162]\n",
      "\n",
      "--2026-02-05 03:25:07--  https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n",
      "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.12, 3.165.160.61, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/e9c9ab082c52b89a2e85b03407638201d088148e94dccd9b127c60226e2a51bf?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27TinyStoriesV2-GPT4-valid.txt%3B+filename%3D%22TinyStoriesV2-GPT4-valid.txt%22%3B&response-content-type=text%2Fplain&Expires=1770265507&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NTA3fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ1ZThkYTk2MzIwYjBlZmU0MGFkZTdhL2U5YzlhYjA4MmM1MmI4OWEyZTg1YjAzNDA3NjM4MjAxZDA4ODE0OGU5NGRjY2Q5YjEyN2M2MDIyNmUyYTUxYmZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Md3XDgHfgbsyFQee4kalYRAg37ieC7LdOTH061hYpMAgEnmM2%7EkYniDWfBcTwqoSCLtX%7Etd3fS4fqrIZl6rY1himtaca93EkKs3Vq-EoI16IYlxAU-lrUmeWKFJNwk6rdYlrPueOFCyponQ6g%7En4qpxmMu%7EG5k527CXqjBKM3hGkmOvCCUp879%7E1zgTPgOPL1KwvyGLY0x0TXBpZJahWF0khoayjEbM-bJ8Y4dSvAz87JwptCV%7E7OmIKYrbYQCNitENvLXuVGGfdqP23B3hh1iNWhzhxd%7Ev4EOg5VpwNJkm04n7aVqzWcIxRqO0bX2VGkKCMDIxKYjaS16pbjnYz%7EQ__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
      "--2026-02-05 03:25:07--  https://us.gcp.cdn.hf.co/xet-bridge-us/645e8da96320b0efe40ade7a/e9c9ab082c52b89a2e85b03407638201d088148e94dccd9b127c60226e2a51bf?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27TinyStoriesV2-GPT4-valid.txt%3B+filename%3D%22TinyStoriesV2-GPT4-valid.txt%22%3B&response-content-type=text%2Fplain&Expires=1770265507&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NTA3fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjQ1ZThkYTk2MzIwYjBlZmU0MGFkZTdhL2U5YzlhYjA4MmM1MmI4OWEyZTg1YjAzNDA3NjM4MjAxZDA4ODE0OGU5NGRjY2Q5YjEyN2M2MDIyNmUyYTUxYmZcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=Md3XDgHfgbsyFQee4kalYRAg37ieC7LdOTH061hYpMAgEnmM2%7EkYniDWfBcTwqoSCLtX%7Etd3fS4fqrIZl6rY1himtaca93EkKs3Vq-EoI16IYlxAU-lrUmeWKFJNwk6rdYlrPueOFCyponQ6g%7En4qpxmMu%7EG5k527CXqjBKM3hGkmOvCCUp879%7E1zgTPgOPL1KwvyGLY0x0TXBpZJahWF0khoayjEbM-bJ8Y4dSvAz87JwptCV%7E7OmIKYrbYQCNitENvLXuVGGfdqP23B3hh1iNWhzhxd%7Ev4EOg5VpwNJkm04n7aVqzWcIxRqO0bX2VGkKCMDIxKYjaS16pbjnYz%7EQ__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
      "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
      "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22502601 (21M) [text/plain]\n",
      "Saving to: ‘TinyStoriesV2-GPT4-valid.txt’\n",
      "\n",
      "TinyStoriesV2-GPT4- 100%[===================>]  21.46M  17.8MB/s    in 1.2s    \n",
      "\n",
      "2026-02-05 03:25:08 (17.8 MB/s) - ‘TinyStoriesV2-GPT4-valid.txt’ saved [22502601/22502601]\n",
      "\n",
      "--2026-02-05 03:25:08--  https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\n",
      "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.12, 3.165.160.61, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/660add462617cc957fd1bc02/58fb91c989ef15907630f573127276d4db6662ab4aff77b929f901146ee9f208?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27owt_train.txt.gz%3B+filename%3D%22owt_train.txt.gz%22%3B&response-content-type=application%2Fgzip&Expires=1770265508&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NTA4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjYwYWRkNDYyNjE3Y2M5NTdmZDFiYzAyLzU4ZmI5MWM5ODllZjE1OTA3NjMwZjU3MzEyNzI3NmQ0ZGI2NjYyYWI0YWZmNzdiOTI5ZjkwMTE0NmVlOWYyMDhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=QKu62ofMhegakH-ZVL5sVtv9DAR6exNKssrgH-oZ7-kUbg-%7Ec4pYpngH59HokZgGYhyHQqeqopkeSWbj32xKJxwQKhDaI8sqD3Gx1qRlXqFS97XVsoDcPeJ4nmJpfd35iF7UKfXbAsx5-2Wgll94hEkFybwpulvIJqghMqlc3bXA5682yDXyGRLDWHzSvENUsU6E86mL2TzKpfVRScM3PDZ1smGScyuguUOqYuNyLutrDNrPtrka6pbJmmvSGqNe1-2jop16MsR8aBWjTe-fKva39RwZdFwUFTTK4-B4oJ1BDS8UV2zqV7zFF34Rq0x2qcAVy6Z5yhVZ0R6-tPsnsw__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
      "--2026-02-05 03:25:08--  https://us.gcp.cdn.hf.co/xet-bridge-us/660add462617cc957fd1bc02/58fb91c989ef15907630f573127276d4db6662ab4aff77b929f901146ee9f208?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27owt_train.txt.gz%3B+filename%3D%22owt_train.txt.gz%22%3B&response-content-type=application%2Fgzip&Expires=1770265508&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NTA4fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjYwYWRkNDYyNjE3Y2M5NTdmZDFiYzAyLzU4ZmI5MWM5ODllZjE1OTA3NjMwZjU3MzEyNzI3NmQ0ZGI2NjYyYWI0YWZmNzdiOTI5ZjkwMTE0NmVlOWYyMDhcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=QKu62ofMhegakH-ZVL5sVtv9DAR6exNKssrgH-oZ7-kUbg-%7Ec4pYpngH59HokZgGYhyHQqeqopkeSWbj32xKJxwQKhDaI8sqD3Gx1qRlXqFS97XVsoDcPeJ4nmJpfd35iF7UKfXbAsx5-2Wgll94hEkFybwpulvIJqghMqlc3bXA5682yDXyGRLDWHzSvENUsU6E86mL2TzKpfVRScM3PDZ1smGScyuguUOqYuNyLutrDNrPtrka6pbJmmvSGqNe1-2jop16MsR8aBWjTe-fKva39RwZdFwUFTTK4-B4oJ1BDS8UV2zqV7zFF34Rq0x2qcAVy6Z5yhVZ0R6-tPsnsw__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
      "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
      "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4591240837 (4.3G) [application/gzip]\n",
      "Saving to: ‘owt_train.txt.gz’\n",
      "\n",
      "owt_train.txt.gz    100%[===================>]   4.28G  67.2MB/s    in 59s     \n",
      "\n",
      "2026-02-05 03:26:07 (74.4 MB/s) - ‘owt_train.txt.gz’ saved [4591240837/4591240837]\n",
      "\n",
      "--2026-02-05 03:28:39--  https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\n",
      "Resolving huggingface.co (huggingface.co)... 3.165.160.11, 3.165.160.59, 3.165.160.12, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.165.160.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://us.gcp.cdn.hf.co/xet-bridge-us/660add462617cc957fd1bc02/dab4f6880340d5aaa3c404d5f7e4750e145cff7454bf9731eee7f633775cf8ab?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27owt_valid.txt.gz%3B+filename%3D%22owt_valid.txt.gz%22%3B&response-content-type=application%2Fgzip&Expires=1770265719&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NzE5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjYwYWRkNDYyNjE3Y2M5NTdmZDFiYzAyL2RhYjRmNjg4MDM0MGQ1YWFhM2M0MDRkNWY3ZTQ3NTBlMTQ1Y2ZmNzQ1NGJmOTczMWVlZTdmNjMzNzc1Y2Y4YWJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=eCOKATLCzlKuMjauMA4jWgNUxO91yuR1dy9atyfY1YDP3us8ZeWWFUIlQdqYWIQkC6jDSIm2nErys%7Eyg5TAm1H7qwl6OnFEmIyBqC0k6F4TW0QjuDBHsk5w9Yq0H4r4%7E0QEk7g3mCYgtmBfwONUVaG3BzkKXECBcmwkl1beHZVnqEEu84Dl1JEQvs%7EU3rRXHjxAYv4Sff20c-vkxDamJwBhRMNs7lYwubaiyoij8Hif7NEWv5wm61iuYhr020pZf%7ELUIUIFtbk%7Ej9HMMGTkgexEU-jOtZ2RaOj0tuSfIU1wsvnObqm1ltgbWLnpW3--%7EVSDtOr34GEIZwn563dKFUw__&Key-Pair-Id=KJLH8B0YWU4Y8M [following]\n",
      "--2026-02-05 03:28:39--  https://us.gcp.cdn.hf.co/xet-bridge-us/660add462617cc957fd1bc02/dab4f6880340d5aaa3c404d5f7e4750e145cff7454bf9731eee7f633775cf8ab?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27owt_valid.txt.gz%3B+filename%3D%22owt_valid.txt.gz%22%3B&response-content-type=application%2Fgzip&Expires=1770265719&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiRXBvY2hUaW1lIjoxNzcwMjY1NzE5fX0sIlJlc291cmNlIjoiaHR0cHM6Ly91cy5nY3AuY2RuLmhmLmNvL3hldC1icmlkZ2UtdXMvNjYwYWRkNDYyNjE3Y2M5NTdmZDFiYzAyL2RhYjRmNjg4MDM0MGQ1YWFhM2M0MDRkNWY3ZTQ3NTBlMTQ1Y2ZmNzQ1NGJmOTczMWVlZTdmNjMzNzc1Y2Y4YWJcXD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=eCOKATLCzlKuMjauMA4jWgNUxO91yuR1dy9atyfY1YDP3us8ZeWWFUIlQdqYWIQkC6jDSIm2nErys%7Eyg5TAm1H7qwl6OnFEmIyBqC0k6F4TW0QjuDBHsk5w9Yq0H4r4%7E0QEk7g3mCYgtmBfwONUVaG3BzkKXECBcmwkl1beHZVnqEEu84Dl1JEQvs%7EU3rRXHjxAYv4Sff20c-vkxDamJwBhRMNs7lYwubaiyoij8Hif7NEWv5wm61iuYhr020pZf%7ELUIUIFtbk%7Ej9HMMGTkgexEU-jOtZ2RaOj0tuSfIU1wsvnObqm1ltgbWLnpW3--%7EVSDtOr34GEIZwn563dKFUw__&Key-Pair-Id=KJLH8B0YWU4Y8M\n",
      "Resolving us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)... 34.120.165.110\n",
      "Connecting to us.gcp.cdn.hf.co (us.gcp.cdn.hf.co)|34.120.165.110|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 111785382 (107M) [application/gzip]\n",
      "Saving to: ‘owt_valid.txt.gz’\n",
      "\n",
      "owt_valid.txt.gz    100%[===================>] 106.61M  47.4MB/s    in 2.2s    \n",
      "\n",
      "2026-02-05 03:28:42 (47.4 MB/s) - ‘owt_valid.txt.gz’ saved [111785382/111785382]\n",
      "\n",
      "\n",
      "=== Download verification ===\n",
      "TinyStoriesV2-GPT4-train.txt: 2.23 GB\n",
      "TinyStoriesV2-GPT4-valid.txt: 0.02 GB\n",
      "owt_train.txt: 11.92 GB\n",
      "owt_valid.txt: 0.29 GB\n",
      "/content/ece405-assignment1-basics\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "\n",
    "# Remove old data folder and start fresh\n",
    "!rm -rf data\n",
    "!mkdir -p data\n",
    "%cd data\n",
    "\n",
    "# Download TinyStories\n",
    "!wget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\n",
    "!wget https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n",
    "\n",
    "# Download OpenWebText sample\n",
    "!wget https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\n",
    "!gunzip owt_train.txt.gz\n",
    "!wget https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\n",
    "!gunzip owt_valid.txt.gz\n",
    "\n",
    "# Verify all downloads\n",
    "import os\n",
    "print(\"\\n=== Download verification ===\")\n",
    "for f in [\"TinyStoriesV2-GPT4-train.txt\", \"TinyStoriesV2-GPT4-valid.txt\", \"owt_train.txt\", \"owt_valid.txt\"]:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"{f}: {size / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"{f}: MISSING!\")\n",
    "\n",
    "%cd /content/ece405-assignment1-basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "num_workers_run"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using num_workers=1\n",
      "Input: /content/data/TinyStoriesV2-GPT4-train.txt\n",
      "Vocab size: 10000\n",
      "Output dir: outputs\n",
      "\n",
      "Starting BPE training...\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_workers = max(1, (os.cpu_count() or 1) - 1)\n",
    "print(f\"Using num_workers={num_workers}\")\n",
    "\n",
    "!python scripts/train_bpe_tinystories.py --input /content/data/TinyStoriesV2-GPT4-train.txt --vocab-size 10000 --output-dir outputs --num-workers {num_workers}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PaMKz1Gg6kvL"
   },
   "outputs": [],
   "source": [
    "# Keep session alive\n",
    "import time\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "def keep_alive():\n",
    "    display(Javascript('function ClickConnect(){console.log(\"Keeping alive\"); document.querySelector(\"colab-connect-button\").click()}setInterval(ClickConnect, 60000)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwfbHtTc7on8",
    "outputId": "5b44ed84-bb09-4de3-e6fd-6a8271e31c27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists! Size: 2.23 GB\n",
      "Line 0: \n",
      "...\n",
      "Line 1: Once upon a time there was a little boy named Ben. Ben loved to explore the world around him. He saw...\n",
      "Line 2: He said, “Wow, that is a really amazing vase! Can I buy it?” \n",
      "...\n",
      "Line 3: The shopkeeper smiled and said, “Of course you can. You can take it home and show all your friends h...\n",
      "Line 4: So Ben took the vase home and he was so proud of it! He called his friends over and showed them the ...\n"
     ]
    }
   ],
   "source": [
    "# Check if the data file exists and has content\n",
    "import os\n",
    "\n",
    "data_path = \"/content/data/TinyStoriesV2-GPT4-train.txt\"\n",
    "\n",
    "if os.path.exists(data_path):\n",
    "    size = os.path.getsize(data_path)\n",
    "    print(f\"File exists! Size: {size / 1e9:.2f} GB\")\n",
    "\n",
    "    # Check first few lines\n",
    "    with open(data_path, 'r') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i < 5:\n",
    "                print(f\"Line {i}: {line[:100]}...\")\n",
    "            else:\n",
    "                break\n",
    "else:\n",
    "    print(\"FILE NOT FOUND!\")\n",
    "    print(\"Contents of /content/data/:\")\n",
    "    !ls -la /content/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aawWReNYEhu6",
    "outputId": "a74d5838-dbf4-4ec1-bae4-14f4bf8bbb88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Reading file...\n",
      "File read: 16.5s, Size: 2.23 GB\n",
      "\n",
      "Step 2: Pre-tokenizing (this might be slow)...\n",
      "  Processed 10M tokens, elapsed: 26.0s\n",
      "  Processed 20M tokens, elapsed: 45.1s\n",
      "  Processed 30M tokens, elapsed: 64.4s\n",
      "  Processed 40M tokens, elapsed: 83.6s\n",
      "  Processed 50M tokens, elapsed: 102.2s\n",
      "  Processed 60M tokens, elapsed: 119.4s\n",
      "  Processed 70M tokens, elapsed: 138.9s\n",
      "  Processed 80M tokens, elapsed: 158.1s\n",
      "  Processed 90M tokens, elapsed: 177.4s\n",
      "  Processed 100M tokens, elapsed: 197.0s\n",
      "  Processed 110M tokens, elapsed: 216.4s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import regex as re\n",
    "from collections import defaultdict\n",
    "from ece496b_basics import _iter_pretokens, GPT2_SPLIT_PATTERN\n",
    "\n",
    "input_path = \"/content/data/TinyStoriesV2-GPT4-train.txt\"\n",
    "special_tokens = [\"<|endoftext|>\"]\n",
    "\n",
    "# Step 1: Time just reading the file\n",
    "print(\"Step 1: Reading file...\")\n",
    "start = time.time()\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "print(f\"File read: {time.time()-start:.1f}s, Size: {len(text)/1e9:.2f} GB\")\n",
    "\n",
    "# Step 2: Time pre-tokenization\n",
    "print(\"\\nStep 2: Pre-tokenizing (this might be slow)...\")\n",
    "start = time.time()\n",
    "pat = re.compile(GPT2_SPLIT_PATTERN)\n",
    "pre_token_counts = defaultdict(int)\n",
    "count = 0\n",
    "for token_bytes in _iter_pretokens(text, special_tokens, pat):\n",
    "    key = tuple(token_bytes)\n",
    "    pre_token_counts[key] += 1\n",
    "    count += 1\n",
    "    if count % 10_000_000 == 0:\n",
    "        print(f\"  Processed {count/1e6:.0f}M tokens, elapsed: {time.time()-start:.1f}s\")\n",
    "\n",
    "print(f\"Pre-tokenization done: {time.time()-start:.1f}s\")\n",
    "print(f\"Total tokens: {count}, Unique pre-tokens: {len(pre_token_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "Wxs6XiAsOdfd",
    "outputId": "5a5baf19-3203-4839-af1b-b4a07de7c32c"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from ece496b_basics import merge_key\n",
    "from collections import defaultdict\n",
    "\n",
    "# We already have pre_token_counts from previous cell\n",
    "print(f\"Starting merge loop with {len(pre_token_counts)} unique pre-tokens\")\n",
    "print(f\"Learning {10000 - 256 - 1} merges...\")\n",
    "\n",
    "vocab = {i: bytes([i]) for i in range(256)}\n",
    "merges_order = []\n",
    "num_merges = 10000 - 256 - 1  # 9743 merges\n",
    "\n",
    "start = time.time()\n",
    "for i in range(num_merges):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"  Merge {i}/{num_merges}, elapsed: {time.time()-start:.1f}s\")\n",
    "\n",
    "    pair_counts = defaultdict(int)\n",
    "    for token, count in pre_token_counts.items():\n",
    "        for j in range(len(token) - 1):\n",
    "            pair_counts[(token[j], token[j + 1])] += count\n",
    "\n",
    "    if not pair_counts:\n",
    "        break\n",
    "\n",
    "    best = None\n",
    "    best_count = -1\n",
    "    best_bytes = None\n",
    "    for p, cnt in pair_counts.items():\n",
    "        if cnt > best_count:\n",
    "            best = p\n",
    "            best_count = cnt\n",
    "            best_bytes = (vocab[p[0]], vocab[p[1]])\n",
    "        elif cnt == best_count:\n",
    "            p_bytes = (vocab[p[0]], vocab[p[1]])\n",
    "            if p_bytes > best_bytes:\n",
    "                best = p\n",
    "                best_bytes = p_bytes\n",
    "\n",
    "    idx = 256 + i\n",
    "    new_pre_token_counts = defaultdict(int)\n",
    "    for token, count in pre_token_counts.items():\n",
    "        new_token, _ = merge_key(token, best, idx)\n",
    "        new_pre_token_counts[new_token] += count\n",
    "\n",
    "    pre_token_counts = new_pre_token_counts\n",
    "    merges_order.append(best)\n",
    "    vocab[idx] = vocab[best[0]] + vocab[best[1]]\n",
    "\n",
    "print(f\"\\nMerge loop done: {time.time()-start:.1f}s\")\n",
    "print(f\"Total merges learned: {len(merges_order)}\")\n",
    "\n",
    "# Add special token\n",
    "vocab[256 + len(merges_order)] = \"<|endoftext|>\".encode(\"utf-8\")\n",
    "\n",
    "# Find longest token\n",
    "longest_id = max(vocab.keys(), key=lambda k: len(vocab[k]))\n",
    "print(f\"\\nLongest token (id={longest_id}): '{vocab[longest_id].decode('utf-8', errors='replace')}'\")\n",
    "print(f\"Length: {len(vocab[longest_id])} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkIajfAYPAr6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "ixKcKPfXNj4o",
    "outputId": "8f109807-bfa7-4ec1-9d83-6edf6108e427"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from ece496b_basics import train_bpe\n",
    "\n",
    "# Quick test with small vocab\n",
    "start = time.time()\n",
    "vocab, merges = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=500,  # Much smaller - only 243 merges\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "print(f\"Time for vocab_size=500: {time.time()-start:.1f} seconds\")\n",
    "print(f\"Vocab size: {len(vocab)}, Merges: {len(merges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGV0qZxuy8Y5"
   },
   "outputs": [],
   "source": [
    "# Train BPE on TinyStories\n",
    "import time\n",
    "import tracemalloc\n",
    "from ece496b_basics import train_bpe\n",
    "import json\n",
    "\n",
    "# Start memory tracking\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the tokenizer\n",
    "vocab, merges = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "# Measure time and memory\n",
    "elapsed_time = time.time() - start_time\n",
    "current_mem, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "print(f\"Peak memory: {peak_mem / 1e9:.2f} GB\")\n",
    "\n",
    "# Find the longest token\n",
    "longest_token_id = max(vocab.keys(), key=lambda k: len(vocab[k]))\n",
    "longest_token = vocab[longest_token_id]\n",
    "print(f\"\\nLongest token (id={longest_token_id}): {longest_token}\")\n",
    "print(f\"Longest token decoded: '{longest_token.decode('utf-8', errors='replace')}'\")\n",
    "print(f\"Length: {len(longest_token)} bytes\")\n",
    "\n",
    "# Save vocab and merges to disk\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    # Convert bytes to hex strings for JSON serialization\n",
    "    vocab_serializable = {k: v.hex() for k, v in vocab.items()}\n",
    "    json.dump(vocab_serializable, f)\n",
    "\n",
    "with open(\"merges.txt\", \"w\") as f:\n",
    "    for a, b in merges:\n",
    "        f.write(f\"{a.hex()} {b.hex()}\\n\")\n",
    "\n",
    "print(\"\\nSaved vocab.json and merges.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yl0PMvxD0EqI"
   },
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "# Profile the training\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "vocab, merges = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "# Print top 20 time-consuming functions\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "ps.print_stats(20)\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
