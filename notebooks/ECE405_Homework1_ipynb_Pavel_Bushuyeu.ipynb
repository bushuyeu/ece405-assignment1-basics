{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijR6qPINU_P6"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/bushuyeu/ece405-assignment1-basics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5eKjGhFMiZ6"
   },
   "outputs": [],
   "source": [
    "%cd ece405-assignment1-basics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uVh85UKdMng8"
   },
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLdwVyZ3MKk8"
   },
   "outputs": [],
   "source": [
    "!git checkout main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUpCszLnfDf1"
   },
   "source": [
    "No need for Conda environment on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D1tPK7iKenBW"
   },
   "outputs": [],
   "source": [
    "!pip install -e .'[test]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-_dABLeW3LR"
   },
   "outputs": [],
   "source": [
    "!pytest tests/test_train_bpe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "5wrA646Gf3Ht"
   },
   "outputs": [],
   "source": [
    "%cd /content\n",
    "\n",
    "# Remove old data folder and start fresh\n",
    "!rm -rf data\n",
    "!mkdir -p data\n",
    "%cd data\n",
    "\n",
    "# Download TinyStories\n",
    "!wget -q --show-progress https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-train.txt\n",
    "!wget -q --show-progress https://huggingface.co/datasets/roneneldan/TinyStories/resolve/main/TinyStoriesV2-GPT4-valid.txt\n",
    "\n",
    "# Download OpenWebText sample\n",
    "!wget -q --show-progress https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_train.txt.gz\n",
    "!gunzip owt_train.txt.gz\n",
    "!wget -q --show-progress https://huggingface.co/datasets/stanford-cs336/owt-sample/resolve/main/owt_valid.txt.gz\n",
    "!gunzip owt_valid.txt.gz\n",
    "\n",
    "# Verify all downloads\n",
    "import os\n",
    "print(\"\\n=== Download verification ===\")\n",
    "for f in [\"TinyStoriesV2-GPT4-train.txt\", \"TinyStoriesV2-GPT4-valid.txt\", \"owt_train.txt\", \"owt_valid.txt\"]:\n",
    "    if os.path.exists(f):\n",
    "        size = os.path.getsize(f)\n",
    "        print(f\"{f}: {size / 1e9:.2f} GB\")\n",
    "    else:\n",
    "        print(f\"{f}: MISSING!\")\n",
    "\n",
    "%cd /content/ece405-assignment1-basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_and_helpers"
   },
   "outputs": [],
   "source": [
    "# Common imports and helper functions\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import tracemalloc\n",
    "from ece496b_basics import train_bpe\n",
    "\n",
    "os.makedirs(\"outputs\", exist_ok=True)\n",
    "\n",
    "def safe_decode(b):\n",
    "    \"\"\"Safely decode bytes to string, falling back to repr if UTF-8 fails.\"\"\"\n",
    "    try:\n",
    "        return b.decode('utf-8')\n",
    "    except:\n",
    "        return repr(b)\n",
    "\n",
    "def analyze_vocab(vocab, name):\n",
    "    \"\"\"Print analysis of a vocabulary.\"\"\"\n",
    "    longest_token = max(vocab.values(), key=len)\n",
    "    avg_len = sum(len(v) for v in vocab.values()) / len(vocab)\n",
    "    \n",
    "    print(f\"\\n{name} Vocabulary Analysis:\")\n",
    "    print(f\"  Total tokens: {len(vocab)}\")\n",
    "    print(f\"  Merged tokens (non-byte): {len([k for k in vocab if k >= 256])}\")\n",
    "    print(f\"  Average token length: {avg_len:.2f} bytes\")\n",
    "    print(f\"  Longest token: '{safe_decode(longest_token)}' ({len(longest_token)} bytes)\")\n",
    "    \n",
    "    # Top 5 longest\n",
    "    print(f\"  Top 5 longest tokens:\")\n",
    "    for tid, tbytes in sorted(vocab.items(), key=lambda x: len(x[1]), reverse=True)[:5]:\n",
    "        print(f\"    ID {tid}: '{safe_decode(tbytes)}' ({len(tbytes)} bytes)\")\n",
    "\n",
    "print(\"Imports and helpers loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tinystories_header"
   },
   "source": [
    "## TinyStories BPE Training (vocab_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ts_training"
   },
   "outputs": [],
   "source": [
    "# Train BPE on TinyStories\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "ts_vocab, ts_merges = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "_, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "print(f\"Peak memory: {peak_mem / 1e9:.2f} GB\")\n",
    "print(f\"Number of merges: {len(ts_merges)}\")\n",
    "\n",
    "analyze_vocab(ts_vocab, \"TinyStories\")\n",
    "\n",
    "# Save immediately\n",
    "with open(\"outputs/ts_vocab_10k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ts_vocab, f)\n",
    "with open(\"outputs/ts_merges_10k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ts_merges, f)\n",
    "print(\"\\nSaved to outputs/ts_vocab_10k.pkl and outputs/ts_merges_10k.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owt_header"
   },
   "source": [
    "## OpenWebText BPE Training (vocab_size=32000)\n",
    "\n",
    "**Problem (train_bpe_expts_owt)**: Train a byte-level BPE tokenizer on OpenWebText with vocab_size=32,000.\n",
    "\n",
    "Resource requirements: ≤12 hours (no GPUs), ≤100GB RAM\n",
    "\n",
    "**Note**: This will take several hours. Consider running overnight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owt_training"
   },
   "outputs": [],
   "source": [
    "# Train BPE on OpenWebText with vocab_size=32000\n",
    "tracemalloc.start()\n",
    "start_time = time.time()\n",
    "\n",
    "owt_vocab, owt_merges = train_bpe(\n",
    "    input_path=\"/content/data/owt_train.txt\",\n",
    "    vocab_size=32000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "_, peak_mem = tracemalloc.get_traced_memory()\n",
    "tracemalloc.stop()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"OpenWebText BPE Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes, {elapsed_time/3600:.2f} hours)\")\n",
    "print(f\"Peak memory: {peak_mem / 1e9:.2f} GB\")\n",
    "print(f\"Number of merges: {len(owt_merges)}\")\n",
    "\n",
    "analyze_vocab(owt_vocab, \"OpenWebText\")\n",
    "\n",
    "# Save immediately\n",
    "with open(\"outputs/owt_vocab_32k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(owt_vocab, f)\n",
    "with open(\"outputs/owt_merges_32k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(owt_merges, f)\n",
    "print(\"\\nSaved to outputs/owt_vocab_32k.pkl and outputs/owt_merges_32k.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "comparison_header"
   },
   "source": "## Compare TinyStories vs OpenWebText Tokenizers\n\n**Problem (train_bpe_expts_owt) Part (b)**: Compare and contrast the tokenizers trained on TinyStories vs OpenWebText."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_load"
   },
   "outputs": [],
   "source": [
    "# Load vocabularies (in case running from fresh kernel after long OWT training)\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    ts_vocab\n",
    "    print(\"TinyStories vocab already in memory\")\n",
    "except NameError:\n",
    "    with open(\"outputs/ts_vocab_10k.pkl\", \"rb\") as f:\n",
    "        ts_vocab = pickle.load(f)\n",
    "    print(\"Loaded TinyStories vocab from disk\")\n",
    "\n",
    "try:\n",
    "    owt_vocab\n",
    "    print(\"OpenWebText vocab already in memory\")\n",
    "except NameError:\n",
    "    with open(\"outputs/owt_vocab_32k.pkl\", \"rb\") as f:\n",
    "        owt_vocab = pickle.load(f)\n",
    "    print(\"Loaded OpenWebText vocab from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_analysis"
   },
   "outputs": [],
   "source": [
    "# Compare token sets (excluding base 256 bytes)\n",
    "ts_tokens = set(v for k, v in ts_vocab.items() if k >= 256)\n",
    "owt_tokens = set(v for k, v in owt_vocab.items() if k >= 256)\n",
    "\n",
    "shared = ts_tokens & owt_tokens\n",
    "ts_only = ts_tokens - owt_tokens\n",
    "owt_only = owt_tokens - ts_tokens\n",
    "\n",
    "print(f\"TinyStories merged tokens: {len(ts_tokens)}\")\n",
    "print(f\"OpenWebText merged tokens: {len(owt_tokens)}\")\n",
    "print(f\"\\nShared tokens: {len(shared)}\")\n",
    "print(f\"  ({len(shared)/len(ts_tokens)*100:.1f}% of TinyStories tokens are in OWT)\")\n",
    "print(f\"  ({len(shared)/len(owt_tokens)*100:.1f}% of OWT tokens are in TinyStories)\")\n",
    "print(f\"\\nTokens unique to TinyStories: {len(ts_only)}\")\n",
    "print(f\"Tokens unique to OpenWebText: {len(owt_only)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_examples"
   },
   "outputs": [],
   "source": [
    "# Helper function (in case cell-8 wasn't run)\n",
    "def safe_decode(b):\n",
    "    try:\n",
    "        return b.decode('utf-8')\n",
    "    except:\n",
    "        return repr(b)\n",
    "\n",
    "# Show example tokens unique to each dataset (sorted by length for interesting examples)\n",
    "print(\"Top 15 longest tokens UNIQUE to TinyStories (children's stories):\")\n",
    "for t in sorted(ts_only, key=len, reverse=True)[:15]:\n",
    "    print(f\"  '{safe_decode(t)}'\")\n",
    "\n",
    "print(f\"\\nTop 15 longest tokens UNIQUE to OpenWebText (web text):\")\n",
    "for t in sorted(owt_only, key=len, reverse=True)[:15]:\n",
    "    print(f\"  '{safe_decode(t)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison_stats"
   },
   "outputs": [],
   "source": [
    "# Compare statistics\n",
    "ts_longest = max(ts_vocab.values(), key=len)\n",
    "owt_longest = max(owt_vocab.values(), key=len)\n",
    "ts_avg_len = sum(len(v) for v in ts_vocab.values()) / len(ts_vocab)\n",
    "owt_avg_len = sum(len(v) for v in owt_vocab.values()) / len(owt_vocab)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Metric':<30} {'TinyStories':>12} {'OpenWebText':>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Vocab size':<30} {len(ts_vocab):>12} {len(owt_vocab):>12}\")\n",
    "print(f\"{'Avg token length (bytes)':<30} {ts_avg_len:>12.2f} {owt_avg_len:>12.2f}\")\n",
    "print(f\"{'Longest token (bytes)':<30} {len(ts_longest):>12} {len(owt_longest):>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"TinyStories longest: '{safe_decode(ts_longest)}'\")\n",
    "print(f\"OpenWebText longest: '{safe_decode(owt_longest)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "answers_header"
   },
   "source": "## Answers to Assignment Questions\n\n### Part (a): What is the longest token in the OWT vocabulary? Does it make sense?\n\n*Fill in your answer here after running the cells above.*\n\n### Part (b): Compare and contrast TinyStories vs OpenWebText tokenizers.\n\n**Important**: Note that this comparison uses different vocab sizes (TinyStories: 10k, OWT: 32k) as specified by the assignment. When writing your answer, acknowledge this limitation and focus on qualitative differences (token types, domain-specific vocabulary) rather than raw token counts.\n\n*Fill in your answer here. Consider:*\n- *The vocab size difference (10k vs 32k) means OWT naturally has more tokens*\n- *What % of TinyStories tokens also appear in OWT? What does this suggest?*\n- *Types of tokens unique to each (children's vocabulary vs web/technical terms)*\n- *Average token length differences and what they indicate about text complexity*"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "profiling_header"
   },
   "source": [
    "## Optional: Profiling (TinyStories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "profiling"
   },
   "outputs": [],
   "source": [
    "# Profile the training to see what takes the most time\n",
    "import cProfile\n",
    "import pstats\n",
    "from io import StringIO\n",
    "\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "\n",
    "vocab_prof, merges_prof = train_bpe(\n",
    "    input_path=\"/content/data/TinyStoriesV2-GPT4-train.txt\",\n",
    "    vocab_size=10000,\n",
    "    special_tokens=[\"<|endoftext|>\"]\n",
    ")\n",
    "\n",
    "profiler.disable()\n",
    "\n",
    "s = StringIO()\n",
    "ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')\n",
    "ps.print_stats(20)\n",
    "print(s.getvalue())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}